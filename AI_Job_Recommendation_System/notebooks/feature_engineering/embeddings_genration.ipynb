{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook Generates the user and job embeddings which is GPU Dependant (CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yousuf\\anaconda3\\envs\\recomend\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "user_data_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\cleaned_data\\skill_list.csv\"\n",
    "job_data_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\cleaned_data\\job_cleaned.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Must have cuda installed separeatly to run on the GPU (Not in requirement.txt not used in production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0+cu118\n",
      "torch CUDA available? True\n",
      "torch CUDA version: 11.8\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torch CUDA available?\", torch.cuda.is_available())\n",
    "print(\"torch CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yousuf\\anaconda3\\envs\\rec_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(file_path, data_type='user'):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file.\n",
    "    - data_type (str): Type of data ('user' for user skills, 'job' for job listings).\n",
    "\n",
    "    Returns:\n",
    "    - List[List[str]] for user skills or List[str] for job listings.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "    if data_type == 'user':\n",
    "        # Assuming the first column contains string representations of lists\n",
    "        data = df.iloc[:, 0].apply(ast.literal_eval).tolist()\n",
    "    elif data_type == 'job':\n",
    "        # Assuming there's a 'text' column with job descriptions\n",
    "        data = df['text'].tolist()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data_type. Choose 'user' or 'job'.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data, model_name='intfloat/e5-small-v2', device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate embeddings for the given data using the specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - data (List[List[str]] or List[str]): Data to encode. For users, list of lists of skills. For jobs, list of job descriptions.\n",
    "    - model_name (str): Name of the SentenceTransformer model to use.\n",
    "    - device (str): Device to use for computation ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of embeddings.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    dim = model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    if not data:\n",
    "        return np.array([])\n",
    "    \n",
    "    if isinstance(data[0], list):\n",
    "        # User skills: list of lists\n",
    "        embeddings = []\n",
    "        for skills in data:\n",
    "            if skills:\n",
    "                embs = model.encode(skills, convert_to_numpy=True, show_progress_bar=False)\n",
    "                embeddings.append(embs.mean(axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(dim))\n",
    "        embeddings = np.vstack(embeddings)\n",
    "    elif isinstance(data[0], str):\n",
    "        # Job descriptions: list of strings\n",
    "        embeddings = model.encode(data, convert_to_numpy=True, show_progress_bar=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data format. Expected list of lists or list of strings.\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embeddings, save_path):\n",
    "    \"\"\"\n",
    "    Save the embeddings to a numpy file.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings (np.ndarray): Embeddings to save.\n",
    "    - save_path (str): Path to save the embeddings.\n",
    "    \"\"\"\n",
    "    np.save(save_path, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_embeddings(model_name, user_data_path, job_data_path, user_save_path, job_save_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate and save embeddings for user skills and job listings.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Name of the SentenceTransformer model to use.\n",
    "    - user_data_path (str): Path to the user skills CSV file.\n",
    "    - job_data_path (str): Path to the job listings CSV file.\n",
    "    - user_save_path (str): Path to save the user embeddings.\n",
    "    - job_save_path (str): Path to save the job embeddings.\n",
    "    - device (str): Device to use for computation ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    # Load user skills\n",
    "    user_skills = load_data(user_data_path, data_type='user')\n",
    "    # Generate user embeddings\n",
    "    user_embeddings = generate_embeddings(user_skills, model_name, device)\n",
    "    # Save user embeddings\n",
    "    save_embeddings(user_embeddings, user_save_path)\n",
    "    \n",
    "    # Load job listings\n",
    "    job_listings = load_data(job_data_path, data_type='job')\n",
    "    # Generate job embeddings\n",
    "    job_embeddings = generate_embeddings(job_listings, model_name, device)\n",
    "    # Save job embeddings\n",
    "    save_embeddings(job_embeddings, job_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name1 = 'intfloat/e5-small-v2'\n",
    "\n",
    "user_save_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\Embeddings\\e5_small\\user_profile_embeddings_e5_small.npy\"\n",
    "job_save_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\Embeddings\\e5_small\\job_embeddings_e5_small.npy\"\n",
    "\n",
    "generate_and_save_embeddings(model_name1, user_data_path, job_data_path, user_save_path, job_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'\n",
    "job_save_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\Embeddings\\sbert\\job_sbert_embedding_norm.npy\"\n",
    "user_save_path = r\"C:\\Yousuf\\DEPI\\Technical\\Mega Projects\\Mega_Project\\DEPI-Mega-project-1\\AI_Job_Recommendation_System\\data\\Processed\\Embeddings\\sbert\\user_sbert_embeddings.npy\"\n",
    "\n",
    "generate_and_save_embeddings(model_name, user_data_path, job_data_path, user_save_path, job_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
