{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Similarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score: 57.50/100\n",
      "Skills: Missing skills: PostgreSQL, Kubernetes, Django\n",
      "Certifications: All required certifications present.\n",
      "Education: Education does not meet job requirements.\n",
      "Experience: Missing experience: python\n",
      "Languages: Languages meet job requirements.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path of the project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', '..'))\n",
    "# Add the project root to Python path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Now you can import from ai package\n",
    "from ai.extractors.resume.resume_extractor import ResumeExtractor\n",
    "from ai.extractors.job.job_extractor import JobExtractor\n",
    "from typing import Dict, Any\n",
    "\n",
    "def compute_matching_score(resume_data: Dict[str, Any], job_data: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Computes a matching score between resume and job description based on key fields.\n",
    "    \n",
    "    Args:\n",
    "        resume_data (Dict[str, Any]): Parsed resume data from ResumeExtractor.\n",
    "        job_data (Dict[str, Any]): Parsed job data from JobExtractor.\n",
    "    \n",
    "    Returns:\n",
    "        float: Matching score between 0 and 100.\n",
    "    \"\"\"\n",
    "    # Define weights for each field\n",
    "    weights = {\n",
    "        \"Skills\": 0.4,\n",
    "        \"Certifications\": 0.2,\n",
    "        \"Education\": 0.15,\n",
    "        \"Experience\": 0.15,\n",
    "        \"Languages\": 0.1\n",
    "    }\n",
    "\n",
    "    # Compute individual field scores\n",
    "    skills_score = compute_skills_score(resume_data.get(\"Skills\", []), job_data.get(\"Skills\", []))\n",
    "    certs_score = compute_certifications_score(resume_data.get(\"Certifications\", []), job_data.get(\"Certifications\", []))\n",
    "    edu_score = compute_education_score(resume_data.get(\"Education\", []), job_data.get(\"Education\", []))\n",
    "    exp_score = 0\n",
    "    lang_score = compute_languages_score(resume_data.get(\"Languages\", []), job_data.get(\"Languages\", []))\n",
    "\n",
    "    # Compute weighted average\n",
    "    total_score = (\n",
    "        skills_score * weights[\"Skills\"] +\n",
    "        certs_score * weights[\"Certifications\"] +\n",
    "        edu_score * weights[\"Education\"] +\n",
    "        exp_score * weights[\"Experience\"] +\n",
    "        lang_score * weights[\"Languages\"]\n",
    "    ) * 100  # Scale to 0-100\n",
    "\n",
    "    return total_score\n",
    "\n",
    "def compute_skills_score(resume_skills: list, job_skills: list) -> float:\n",
    "    if not job_skills:\n",
    "        return 1.0\n",
    "    matching_skills = set(resume_skills).intersection(set(job_skills))\n",
    "    return len(matching_skills) / len(job_skills)\n",
    "\n",
    "def compute_certifications_score(resume_certs: list, job_certs: list) -> float:\n",
    "    if not job_certs:\n",
    "        return 1.0\n",
    "    matching_certs = set(resume_certs).intersection(set(job_certs))\n",
    "    return len(matching_certs) / len(job_certs)\n",
    "\n",
    "def compute_education_score(resume_edu: list, job_edu: list) -> float:\n",
    "    if not job_edu:\n",
    "        return 1.0\n",
    "    resume_edu_set = set(resume_edu)\n",
    "    job_edu_set = set(job_edu)\n",
    "    return 1.0 if job_edu_set.issubset(resume_edu_set) else 0.0\n",
    "\n",
    "def compute_experience_score(resume_exp: list, job_exp: list) -> float:\n",
    "    if not job_exp:\n",
    "        return 1.0\n",
    "    matching_exp = set(resume_exp).intersection(set(job_exp))\n",
    "    return len(matching_exp) / len(job_exp)\n",
    "\n",
    "def compute_languages_score(resume_langs: list, job_langs: list) -> float:\n",
    "    if not job_langs:\n",
    "        return 1.0\n",
    "    matching_langs = set(resume_langs).intersection(set(job_langs))\n",
    "    return len(matching_langs) / len(job_langs)\n",
    "\n",
    "def generate_feedback(resume_data: Dict[str, Any], job_data: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates feedback based on differences between resume and job requirements.\n",
    "    \n",
    "    Args:\n",
    "        resume_data (Dict[str, Any]): Parsed resume data.\n",
    "        job_data (Dict[str, Any]): Parsed job data.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: Feedback for each field.\n",
    "    \"\"\"\n",
    "    feedback = {}\n",
    "\n",
    "    # Skills feedback\n",
    "    missing_skills = set(job_data.get(\"Skills\", [])) - set(resume_data.get(\"Skills\", []))\n",
    "    feedback[\"Skills\"] = f\"Missing skills: {', '.join(missing_skills)}\" if missing_skills else \"All required skills present.\"\n",
    "\n",
    "    # Certifications feedback\n",
    "    missing_certs = set(job_data.get(\"Certifications\", [])) - set(resume_data.get(\"Certifications\", []))\n",
    "    feedback[\"Certifications\"] = f\"Missing certifications: {', '.join(missing_certs)}\" if missing_certs else \"All required certifications present.\"\n",
    "\n",
    "    # Education feedback\n",
    "    if not set(job_data.get(\"Education\", [])).issubset(set(resume_data.get(\"Education\", []))):\n",
    "        feedback[\"Education\"] = \"Education does not meet job requirements.\"\n",
    "    else:\n",
    "        feedback[\"Education\"] = \"Education meets job requirements.\"\n",
    "\n",
    "    # Experience feedback\n",
    "    missing_exp = set(job_data.get(\"Experience\", [])) - set(resume_data.get(\"Experience\", []))\n",
    "    feedback[\"Experience\"] = f\"Missing experience: {', '.join(missing_exp)}\" if missing_exp else \"Experience meets job requirements.\"\n",
    "\n",
    "    # Languages feedback\n",
    "    missing_langs = set(job_data.get(\"Languages\", [])) - set(resume_data.get(\"Languages\", []))\n",
    "    feedback[\"Languages\"] = f\"Missing languages: {', '.join(missing_langs)}\" if missing_langs else \"Languages meet job requirements.\"\n",
    "\n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    resume_text = \"\"\"\n",
    "    John Doe\n",
    "    Email: john.doe@example.com\n",
    "    Phone: +1 (555) 123-4567\n",
    "    LinkedIn: linkedin.com/in/johndoe\n",
    "    GitHub: github.com/johndoe\n",
    "\n",
    "    Skills:\n",
    "    Python, JavaScript, React, FastAPI, Docker, SQL, Machine Learning\n",
    "\n",
    "    Experience\n",
    "    Software Engineer – OpenAI\n",
    "    2021 – Present\n",
    "    - Built RESTful APIs using FastAPI and deployed models on AWS\n",
    "    - Collaborated on NLP models for document understanding\n",
    "\n",
    "    Certifications\n",
    "    AWS Certified Solutions Architect – Associate\n",
    "    TensorFlow Developer Certificate\n",
    "\n",
    "    Languages\n",
    "    English, French, Arabic\n",
    "    \"\"\"\n",
    "\n",
    "    job_text = \"\"\"\n",
    "    We're seeking a backend engineer with 3+ years of experience in Django and PostgreSQL.\n",
    "    Required: Bachelor's degree in Computer Science or related field.\n",
    "    Certifications like AWS Certified Solutions Architect or AZ-900 are a plus.\n",
    "    Must be fluent in English and familiar with Docker, Kubernetes, and React.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse resume and job description\n",
    "    resume_extractor = ResumeExtractor()\n",
    "    job_extractor = JobExtractor()\n",
    "\n",
    "    resume_data = resume_extractor.parse(resume_text)\n",
    "    job_data = job_extractor.parse(job_text)\n",
    "\n",
    "    # Compute score\n",
    "    score = compute_matching_score(resume_data, job_data)\n",
    "    print(f\"Matching Score: {score:.2f}/100\")\n",
    "\n",
    "    # Generate and print feedback\n",
    "    feedback = generate_feedback(resume_data, job_data)\n",
    "    for field, message in feedback.items():\n",
    "        print(f\"{field}: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosin Similarty and Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score: 51.68/100\n",
      "Skills: Missing skills: TensorFlow\n",
      "Certifications: Missing certifications: Proven track record of delivering AI/ML projects.\n",
      "Education: Education meets job requirements.\n",
      "Experience: Experience meets job requirements.\n",
      "Languages: Languages meet job requirements.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Get the absolute path of the project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', '..'))\n",
    "# Add the project root to Python path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import extractors\n",
    "from ai.extractors.resume.resume_extractor import ResumeExtractor\n",
    "from ai.extractors.job.job_extractor import JobExtractor\n",
    "\n",
    "# Load SBERT model once at the beginning\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def compute_matching_score(resume_data: Dict[str, Any], job_data: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Computes a matching score between resume and job description based on key fields.\n",
    "    \n",
    "    Args:\n",
    "        resume_data (Dict[str, Any]): Parsed resume data from ResumeExtractor.\n",
    "        job_data (Dict[str, Any]): Parsed job data from JobExtractor.\n",
    "    \n",
    "    Returns:\n",
    "        float: Matching score between 0 and 100.\n",
    "    \"\"\"\n",
    "    # Define weights for each field\n",
    "    weights = {\n",
    "        \"Skills\": 0.4,\n",
    "        \"Certifications\": 0.2,\n",
    "        \"Education\": 0.15,\n",
    "        \"Experience\": 0.15,\n",
    "        \"Languages\": 0.1\n",
    "    }\n",
    "\n",
    "    # Compute individual field scores\n",
    "    skills_score = compute_skills_score(resume_data.get(\"Skills\", []), job_data.get(\"Skills\", []))\n",
    "    certs_score = compute_certifications_score(resume_data.get(\"Certifications\", []), job_data.get(\"Certifications\", []))\n",
    "    edu_score = compute_education_score(resume_data.get(\"Education\", []), job_data.get(\"Education\", []))\n",
    "    exp_score = compute_experience_score(resume_data.get(\"Experience\", []), job_data.get(\"Experience\", []))\n",
    "    lang_score = compute_languages_score(resume_data.get(\"Languages\", []), job_data.get(\"Languages\", []))\n",
    "\n",
    "    # Compute weighted average\n",
    "    total_score = (\n",
    "        skills_score * weights[\"Skills\"] +\n",
    "        certs_score * weights[\"Certifications\"] +\n",
    "        edu_score * weights[\"Education\"] +\n",
    "        exp_score * weights[\"Experience\"] +\n",
    "        lang_score * weights[\"Languages\"]\n",
    "    ) * 100  # Scale to 0-100\n",
    "\n",
    "    return total_score\n",
    "\n",
    "def compute_skills_score(resume_skills: list, job_skills: list) -> float:\n",
    "    \"\"\"Calculate score based on exact skill matches.\"\"\"\n",
    "    if not job_skills:\n",
    "        return 1.0\n",
    "    matching_skills = set(resume_skills).intersection(set(job_skills))\n",
    "    return len(matching_skills) / len(job_skills)\n",
    "\n",
    "def compute_certifications_score(resume_certs: list, job_certs: list) -> float:\n",
    "    \"\"\"Calculate score based on exact certification matches.\"\"\"\n",
    "    if not job_certs:\n",
    "        return 1.0\n",
    "    matching_certs = set(resume_certs).intersection(set(job_certs))\n",
    "    return len(matching_certs) / len(job_certs)\n",
    "\n",
    "def compute_education_score(resume_edu: list, job_edu: list) -> float:\n",
    "    \"\"\"Calculate education score using SBERT semantic similarity.\"\"\"\n",
    "    if not job_edu:\n",
    "        return 1.0\n",
    "    if not resume_edu:\n",
    "        return 0.0\n",
    "    resume_edu_embeddings = sbert_model.encode(resume_edu)\n",
    "    job_edu_embeddings = sbert_model.encode(job_edu)\n",
    "    similarities = util.cos_sim(job_edu_embeddings, resume_edu_embeddings)\n",
    "    max_similarities = similarities.max(dim=1).values  # Max similarity for each job requirement\n",
    "    avg_max_similarity = max_similarities.mean().item()  # Average of max similarities\n",
    "    return avg_max_similarity\n",
    "\n",
    "def compute_experience_score(resume_exp: list, job_exp: list) -> float:\n",
    "    \"\"\"Calculate experience score using SBERT semantic similarity.\"\"\"\n",
    "    if not job_exp:\n",
    "        return 1.0\n",
    "    # Extract descriptions from resume experience (list of dicts)\n",
    "    resume_descriptions = [exp[\"Description\"] for exp in resume_exp if \"Description\" in exp]\n",
    "    if not resume_descriptions:\n",
    "        return 0.0\n",
    "    resume_exp_embeddings = sbert_model.encode(resume_descriptions)\n",
    "    job_exp_embeddings = sbert_model.encode(job_exp)\n",
    "    similarities = util.cos_sim(job_exp_embeddings, resume_exp_embeddings)\n",
    "    max_similarities = similarities.max(dim=1).values  # Max similarity for each job requirement\n",
    "    avg_max_similarity = max_similarities.mean().item()  # Average of max similarities\n",
    "    return avg_max_similarity\n",
    "\n",
    "def compute_languages_score(resume_langs: list, job_langs: list) -> float:\n",
    "    \"\"\"Calculate score based on exact language matches.\"\"\"\n",
    "    if not job_langs:\n",
    "        return 1.0\n",
    "    matching_langs = set(resume_langs).intersection(set(job_langs))\n",
    "    return len(matching_langs) / len(job_langs)\n",
    "\n",
    "def generate_feedback(resume_data: Dict[str, Any], job_data: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates feedback based on differences between resume and job requirements.\n",
    "    \n",
    "    Args:\n",
    "        resume_data (Dict[str, Any]): Parsed resume data.\n",
    "        job_data (Dict[str, Any]): Parsed job data.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: Feedback for each field.\n",
    "    \"\"\"\n",
    "    feedback = {}\n",
    "\n",
    "    # Skills feedback\n",
    "    missing_skills = set(job_data.get(\"Skills\", [])) - set(resume_data.get(\"Skills\", []))\n",
    "    feedback[\"Skills\"] = f\"Missing skills: {', '.join(missing_skills)}\" if missing_skills else \"All required skills present.\"\n",
    "\n",
    "    # Certifications feedback\n",
    "    missing_certs = set(job_data.get(\"Certifications\", [])) - set(resume_data.get(\"Certifications\", []))\n",
    "    feedback[\"Certifications\"] = f\"Missing certifications: {', '.join(missing_certs)}\" if missing_certs else \"All required certifications present.\"\n",
    "\n",
    "    # Education feedback\n",
    "    edu_score = compute_education_score(resume_data.get(\"Education\", []), job_data.get(\"Education\", []))\n",
    "    feedback[\"Education\"] = \"Education may not fully meet job requirements.\" if edu_score < 0 else \"Education meets job requirements.\"\n",
    "\n",
    "    # Experience feedback\n",
    "    exp_score = compute_experience_score(resume_data.get(\"Experience\", []), job_data.get(\"Experience\", []))\n",
    "    feedback[\"Experience\"] = \"Experience may not fully meet job requirements.\" if exp_score < 0 else \"Experience meets job requirements.\"\n",
    "\n",
    "    # Languages feedback\n",
    "    missing_langs = set(job_data.get(\"Languages\", [])) - set(resume_data.get(\"Languages\", []))\n",
    "    feedback[\"Languages\"] = f\"Missing languages: {', '.join(missing_langs)}\" if missing_langs else \"Languages meet job requirements.\"\n",
    "\n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    resume_text = \"\"\"\n",
    "    Ahmed Mostafa\n",
    "Senior Software Engineer | Backend & ML Specialist\n",
    "Cairo, Egypt | ahmed.dev[at]gmail[dot]com | +20 100 123 4567 | linkedin.com/in/ahmedmostafa | github.com/ahmeddev\n",
    "\n",
    "Summary:\n",
    "Results-driven backend engineer with 6+ years of experience designing scalable systems using Python, FastAPI, PostgreSQL, and Docker. Proficient in building machine learning pipelines, deploying models to production with MLflow and Streamlit. Strong advocate for clean code, CI/CD, and agile development.\n",
    "\n",
    "Skills:\n",
    "- Programming: Python, JavaScript, SQL, C++\n",
    "- ML/AI: Scikit-learn, PyTorch, Transformers, XGBoost, Hugging Face, LangChain\n",
    "- Web: FastAPI, Flask, Django, React, Next.js, Tailwind CSS\n",
    "- Databases: PostgreSQL, MySQL, MongoDB, Redis\n",
    "- DevOps: Docker, Kubernetes, GitHub Actions, Terraform, AWS, GCP\n",
    "- Tools: Jupyter, VS Code, Git, Postman, Slack, Notion\n",
    "- Soft Skills: Problem Solving, Teamwork, Communication, Leadership, Critical Thinking\n",
    "\n",
    "Experience:\n",
    "Senior Backend Engineer – DataStack AI (Remote)\n",
    "Aug 2021 – Present\n",
    "- Built a scalable FastAPI backend for a recommendation engine with PostgreSQL & Redis.\n",
    "- Containerized applications using Docker and deployed to GCP with Kubernetes.\n",
    "- Developed automated CI/CD pipelines using GitHub Actions.\n",
    "- Collaborated cross-functionally with frontend and ML teams using Agile.\n",
    "\n",
    "Machine Learning Engineer – TechNova Labs\n",
    "Jan 2019 – Jul 2021\n",
    "- Deployed NLP models for resume parsing and classification using Hugging Face Transformers.\n",
    "- Trained and tuned models with Scikit-learn, PyTorch, and MLflow.\n",
    "- Developed an interactive data dashboard with Streamlit and Plotly.\n",
    "\n",
    "Education:\n",
    "Bachelor of Computer Science, Cairo University, 2018\n",
    "GPA: 3.7 / 4.0\n",
    "\n",
    "Certifications:\n",
    "- AWS Certified Solutions Architect (2023–2026)\n",
    "- Google Cloud Professional ML Engineer\n",
    "- Microsoft Azure Fundamentals (AZ-900)\n",
    "- Deep Learning Specialization – Coursera (Andrew Ng)\n",
    "- ITIL v4 Foundation\n",
    "- Certified Kubernetes Administrator (CKA)\n",
    "\n",
    "Projects:\n",
    "AI Resume Analyzer\n",
    "- Built a Streamlit app that extracts and analyzes resume data using NLP and BERT NER.\n",
    "- Features: skill matching, email & phone extraction, certification parser.\n",
    "\n",
    "E-commerce REST API\n",
    "- Designed a secure REST API using Django REST Framework.\n",
    "- Integrated Stripe payments and user authentication with JWT.\n",
    "\n",
    "Languages:\n",
    "- Arabic (Native)\n",
    "- English (Fluent)\n",
    "- German (Intermediate)\n",
    "\n",
    "Interests:\n",
    "- Open source contributions\n",
    "- AI ethics & fairness\n",
    "- Playing chess & learning languages\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    job_text = \"\"\"\n",
    "    About the job\n",
    "Introduction\n",
    "\n",
    "In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n",
    "\n",
    "A career in IBM Consulting is rooted by long-term relationships and close collaboration with clients across the globe.\n",
    "\n",
    "You'll work with visionaries across multiple industries to improve the hybrid cloud and AI journey for the most innovative and valuable companies in the world. Your ability to accelerate impact and make meaningful change for your clients is enabled by our strategic partner ecosystem and our robust technology platforms across the IBM portfolio; including Software and Red Hat.\n",
    "\n",
    "Curiosity and a constant quest for knowledge serve as the foundation to success in IBM Consulting. In your role, you'll be encouraged to challenge the norm, investigate ideas outside of your role, and come up with creative solutions resulting in ground breaking impact for a wide network of clients. Our culture of evolution and empathy centers on long-term career growth and development opportunities in an environment that embraces your unique skills and experience.\n",
    "\n",
    "Your Role And Responsibilities\n",
    "\n",
    "We are seeking an experienced Data Scientist. The ideal candidate will have a deep understanding of Machine Learning, Generative AI, and Large Language Models, combined with strong leadership abilities. This role will be responsible for business development, overseeing the development and implementation of advanced data-driven solutions as well as mentor a team of talented data scientists.\n",
    "\n",
    "Technical Oversight\n",
    "\n",
    "Oversee the design, development, and deployment of Machine Learning models and AI solutions.\n",
    "Ensure the use of best practices in data science, including model validation, performance monitoring, and continuous improvement.\n",
    "Stay informed about the latest developments in AI/ML and drive the adoption of relevant technologies within the team.\n",
    "\n",
    "Team Development\n",
    "\n",
    "Provide mentorship and professional development opportunities to project and practice team members.\n",
    "Actively support in recruitment efforts to attract top talent and grow the team as needed.\n",
    "Help Foster a culture of learning and continuous development within the AI/Data Science team.\n",
    "\n",
    "Preferred Education\n",
    "\n",
    "Master's Degree\n",
    "\n",
    "Experience\n",
    "\n",
    "Required technical and professional expertise\n",
    "\n",
    "7+ years of experience in Data Science and Machine Learning with at least 1 year of experience in conversational solutions design and development using Watson Assistant or similar conversational AI platforms.\n",
    "Proven track record of delivering AI/ML projects.\n",
    "Experience with Generative AI and Large Language Models is highly desirable\n",
    "\n",
    "Technical Skills\n",
    "\n",
    "Proficiency in programming languages such as Python, R, or Scala.\n",
    "Deep understanding of Machine Learning frameworks (e.g., TensorFlow, PyTorch) and data processing tools (e.g., SQL, Pandas).\n",
    "Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and machine learning deployment.\n",
    "Strong knowledge of Natural Language Processing (NLP) and AI ethics.\n",
    "\n",
    "Leadership Skills\n",
    "\n",
    "Leadership skills with the ability to inspire and motivate junior team members.\n",
    "Strategic thinking with the ability to align data science initiatives with business objectives.\n",
    "Very good communication skills, capable of conveying complex ideas to a variety of audiences.\n",
    "Proven ability to work collaboratively in projects with cross-functional teams.\n",
    "Experience in building/scaling data science teams and implementing AI solutions in a large (preferably, consulting) organization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse resume and job description\n",
    "    resume_extractor = ResumeExtractor()\n",
    "    job_extractor = JobExtractor()\n",
    "\n",
    "    resume_data = resume_extractor.parse(resume_text)\n",
    "    job_data = job_extractor.parse(job_text)\n",
    "\n",
    "    # Compute score\n",
    "    score = compute_matching_score(resume_data, job_data)\n",
    "    print(f\"Matching Score: {score:.2f}/100\")\n",
    "\n",
    "    # Generate and print feedback\n",
    "    feedback = generate_feedback(resume_data, job_data)\n",
    "    for field, message in feedback.items():\n",
    "        print(f\"{field}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_experience_score(resume_exp: list, job_exp: list) -> float:\n",
    "    \"\"\"Calculate experience score using SBERT semantic similarity.\"\"\"\n",
    "    if not job_exp:\n",
    "        return 1.0\n",
    "    # Extract descriptions from resume experience (list of dicts)\n",
    "    resume_descriptions = [exp[\"Description\"] for exp in resume_exp if \"Description\" in exp]\n",
    "    if not resume_descriptions:\n",
    "        return 0.0\n",
    "    resume_exp_embeddings = sbert_model.encode(resume_descriptions)\n",
    "    job_exp_embeddings = sbert_model.encode(job_exp)\n",
    "    similarities = util.cos_sim(job_exp_embeddings, resume_exp_embeddings)\n",
    "    max_similarities = similarities.max(dim=1).values  # Max similarity for each job requirement\n",
    "    avg_max_similarity = max_similarities.mean().item()  # Average of max similarities\n",
    "    return avg_max_similarity\n",
    "\n",
    "def compute_education_score(resume_edu: list, job_edu: list) -> float:\n",
    "    \"\"\"Calculate education score using SBERT semantic similarity.\"\"\"\n",
    "    if not job_edu:\n",
    "        return 1.0\n",
    "    if not resume_edu:\n",
    "        return 0.0\n",
    "    resume_edu_embeddings = sbert_model.encode(resume_edu)\n",
    "    job_edu_embeddings = sbert_model.encode(job_edu)\n",
    "    similarities = util.cos_sim(job_edu_embeddings, resume_edu_embeddings)\n",
    "    max_similarities = similarities.max(dim=1).values  # Max similarity for each job requirement\n",
    "    avg_max_similarity = max_similarities.mean().item()  # Average of max similarities\n",
    "    return avg_max_similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Title': 'Senior Backend Engineer',\n",
       "  'Company': 'DataStack AI (Remote)',\n",
       "  'Date': '2021 – Present',\n",
       "  'Raw': 'Senior Backend Engineer – DataStack AI (Remote)',\n",
       "  'Description': '- Programming: Python, JavaScript, SQL, C++ - ML/AI: Scikit-learn, PyTorch, Transformers, XGBoost, Hugging Face, LangChain - Web: FastAPI, Flask, Django, React, Next.js, Tailwind CSS - Databases: PostgreSQL, MySQL, MongoDB, Redis - DevOps: Docker, Kubernetes, GitHub Actions, Terraform, AWS, GCP - Tools: Jupyter, VS Code, Git, Postman, Slack, Notion - Soft Skills: Problem Solving, Teamwork, Communication, Leadership, Critical Thinking - Built a scalable FastAPI backend for a recommendation engine with PostgreSQL & Redis. - Containerized applications using Docker and deployed to GCP with Kubernetes. - Developed automated CI/CD pipelines using GitHub Actions. - Collaborated cross-functionally with frontend and ML teams using Agile.'},\n",
       " {'Title': 'Machine Learning Engineer',\n",
       "  'Company': 'TechNova Labs',\n",
       "  'Date': None,\n",
       "  'Raw': 'Machine Learning Engineer – TechNova Labs',\n",
       "  'Description': '- Deployed NLP models for resume parsing and classification using Hugging Face Transformers. - Trained and tuned models with Scikit-learn, PyTorch, and MLflow. - Developed an interactive data dashboard with Streamlit and Plotly.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.get(\"Experience\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.get(\"Education\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.3787500262260437\n"
     ]
    }
   ],
   "source": [
    "edu_score = compute_education_score(resume_data.get(\"Education\", []), job_data.get(\"Education\", []))\n",
    "exp_score = compute_experience_score(resume_data.get(\"Experience\", []), job_data.get(\"Experience\", []))\n",
    "\n",
    "print(edu_score)\n",
    "print(exp_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
